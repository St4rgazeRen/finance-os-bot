import os
import requests
import json
import base64
import urllib3
import re
import concurrent.futures
from datetime import datetime, timedelta, timezone
from dotenv import load_dotenv

# --- é—œé–‰ SSL è­¦å‘Š ---
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- ğŸ”¥ è¼‰å…¥ç’°å¢ƒè®Šæ•¸ ---
load_dotenv(override=True)

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
NOTION_TOKEN = os.getenv("NOTION_TOKEN")
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
LINE_USER_ID = os.getenv("LINE_USER_ID")

# è³‡æ–™åº« IDs
NOTION_HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

# --- é ˜åŸŸèˆ‡è³‡æ–™åº«è¨­å®š ---
GLOBAL_DBS = ["FLASH_DB_ID", "LITERATURE_DB_ID", "PERMAMENT_DB_ID"]
DOMAIN_MAP = {
    "INVESTMENT": ["DB_TW_STOCK", "DB_US_STOCK", "DB_CRYPTO", "DB_GOLD", "PAY_LOSS_DB_ID", "DB_SNAPSHOT"],
    "FINANCE": ["TRANSACTIONS_DB_ID", "BUDGET_DB_ID", "INCOME_DB_ID", "DB_ACCOUNT", "DB_MORTGAGE"],
    "HEALTH": ["DIET_DB_ID"],
    "KNOWLEDGE": GLOBAL_DBS
}

FINANCE_DATE_PROP = "æ—¥æœŸ" 
MODEL_NAME = "gemini-2.5-flash"

def ask_gemini_json(prompt):
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent?key={GOOGLE_API_KEY}"
    headers = {"Content-Type": "application/json"}
    data = {"contents": [{"parts": [{"text": prompt}]}]}
    try:
        # Timeout è¨­ç‚º 90 ç§’ï¼Œå› ç‚º 200 ç­†è³‡æ–™è™•ç†éœ€è¦æ™‚é–“
        r = requests.post(url, headers=headers, json=data, verify=False, timeout=90)
        if r.status_code == 200:
            raw = r.json()['candidates'][0]['content']['parts'][0]['text']
            match = re.search(r'\{.*\}', raw, re.DOTALL)
            if match:
                return json.loads(match.group(0))
            else:
                match_list = re.search(r'\[.*\]', raw, re.DOTALL)
                return json.loads(match_list.group(0)) if match_list else None
    except Exception as e:
        print(f"âŒ Gemini Error: {e}")
    return None

def analyze_query_intent(user_query):
    now_str = datetime.now().strftime("%Y-%m-%d")
    prompt = f"""
    ä»Šå¤©æ˜¯ {now_str}ã€‚ä½¿ç”¨è€…å•ï¼š"{user_query}"
    
    è«‹åšå…©ä»¶äº‹ï¼š
    1. åˆ¤æ–·é ˜åŸŸ (INVESTMENT, FINANCE, HEALTH, KNOWLEDGE, OTHER)ã€‚
    2. è§£ææ™‚é–“ç¯„åœ start_date å’Œ end_date (YYYY-MM-DD)ã€‚
       - è‹¥ç„¡ç‰¹å®šæ™‚é–“ï¼Œç•™ç©ºå­—ä¸² ""ã€‚
       - å¦‚æœæ˜¯æ¯”è¼ƒå…©å€‹æœˆ(å¦‚"æœ¬æœˆè·Ÿä¸Šå€‹æœˆ")ï¼Œstart_date å¿…é ˆåŒ…å«è¼ƒæ—©çš„é‚£å€‹æœˆä»½çš„ç¬¬ä¸€å¤©ã€‚
    
    å›å‚³ JSON:
    {{
        "domain": "FINANCE",
        "date_filter": {{ "start": "2026-01-01", "end": "2026-02-11" }} 
    }}
    """
    return ask_gemini_json(prompt)

def extract_notion_value(prop):
    p_type = prop.get("type")
    if p_type == "title": return prop["title"][0]["plain_text"] if prop["title"] else ""
    elif p_type == "rich_text": return prop["rich_text"][0]["plain_text"] if prop["rich_text"] else ""
    elif p_type == "number": return prop["number"]
    elif p_type == "select": return prop["select"]["name"] if prop["select"] else ""
    elif p_type == "status": return prop["status"]["name"] if prop["status"] else ""
    elif p_type == "date": return prop["date"]["start"] if prop["date"] else ""
    elif p_type == "formula":
        f = prop["formula"]
        if f["type"] == "number": return f["number"]
        if f["type"] == "string": return f["string"]
    elif p_type == "rollup":
        if prop["rollup"]["type"] == "number": return prop["rollup"]["number"]
    return None

def fetch_page_content(page_id):
    url = f"https://api.notion.com/v1/blocks/{page_id}/children?page_size=30" # ç¨å¾®æ¸›å°‘ block è®€å–é‡ä»¥æå‡æ•ˆèƒ½
    try:
        r = requests.get(url, headers=NOTION_HEADERS, verify=False)
        data = r.json()
        content_text = ""
        for block in data.get("results", []):
            b_type = block.get("type")
            if b_type in ["paragraph", "heading_1", "heading_2", "heading_3", "bulleted_list_item", "numbered_list_item", "to_do"]:
                rich_text = block.get(b_type, {}).get("rich_text", [])
                if rich_text:
                    content_text += rich_text[0].get("plain_text", "") + "\n"
        return content_text
    except:
        return ""

def fetch_notion_data(db_env_key, domain, date_filter=None):
    db_id = os.getenv(db_env_key)
    if not db_id: return []

    # ğŸ”¥ å„ªåŒ– 2ï¼šå¦‚æœæœ‰æ—¥æœŸéæ¿¾ï¼Œä¸Šé™æå‡åˆ° 200 ç­†ï¼›å¦å‰‡ 30 ç­†
    limit = 200 if (date_filter and date_filter.get("start")) else 30
    
    payload = {"page_size": limit}
    
    if date_filter and date_filter.get("start"):
        date_prop = FINANCE_DATE_PROP if domain == "FINANCE" else None 
        filter_condition = {
            "and": [{"property": date_prop, "date": {"on_or_after": date_filter["start"]}}]
        }
        if date_filter.get("end"):
            filter_condition["and"].append({"property": date_prop, "date": {"on_or_before": date_filter["end"]}})

        if not date_prop:
             payload["filter"] = {"timestamp": "created_time", "created_time": {"on_or_after": date_filter["start"]}}
        else:
            payload["filter"] = filter_condition
            
    if domain in ["FINANCE", "HEALTH", "INVESTMENT"]:
         payload["sorts"] = [{"timestamp": "created_time", "direction": "descending"}]

    try:
        r = requests.post(f"https://api.notion.com/v1/databases/{db_id}/query", headers=NOTION_HEADERS, json=payload, verify=False)
        data = r.json()
        results = []
        fetch_content_flag = (domain == "KNOWLEDGE")

        for page in data.get("results", []):
            simple = {} # ä¸å­˜ ID äº†ï¼Œé™¤éè¦æŠ“å…§æ–‡ï¼Œç¯€çœè¨˜æ†¶é«”
            if fetch_content_flag: simple["id"] = page["id"]

            for k, v in page["properties"].items():
                val = extract_notion_value(v)
                # ğŸ”¥ å„ªåŒ– 3ï¼šåªä¿ç•™æœ‰å€¼çš„æ¬„ä½ï¼Œä¸”éæ¿¾æ‰ä¸€äº›ç³»çµ±æ¬„ä½å¦‚æœä¸éœ€è¦
                if val is not None and val != "": 
                    simple[k] = val
            
            if fetch_content_flag:
                content = fetch_page_content(page["id"])
                if content:
                    simple["content_body"] = content[:500] # é™åˆ¶å…§æ–‡é•·åº¦
                del simple["id"] # ç”¨å®Œå°±ä¸Ÿ
            
            results.append(simple)
        return results
    except Exception as e:
        print(f"Fetch Error ({db_env_key}): {e}")
        return []

def generate_rag_response(user_query, domain, raw_data):
    context = json.dumps(raw_data, ensure_ascii=False, indent=2)
    # ğŸ”¥ å„ªåŒ– 3ï¼šé™åˆ¶ Context é•·åº¦ç‚º 60000 å­—å…ƒï¼Œé˜²æ­¢ Memory Error
    if len(context) > 60000: 
        print(f"âš ï¸ Context éé•· ({len(context)} chars)ï¼Œé€²è¡Œæˆªæ–·...")
        context = context[:60000] + "...(ç•¥)"

    prompt = f"""
    ä½ æ˜¯ AI è²¡å‹™èˆ‡ç”Ÿæ´»åŠ©ç†ã€‚ä½¿ç”¨è€…å•ï¼š"{user_query}"
    è³‡æ–™åº« ({domain}) ç´€éŒ„ï¼š
    {context}
    
    è«‹å›å‚³ JSON ç‰©ä»¶ï¼š
    1. "card_data": UI æ‘˜è¦
       - title: æ¨™é¡Œ (ç²¾ç°¡æœ‰åŠ›)
       - main_stat: æ ¸å¿ƒæ•¸æ“š (å¦‚ "NT$52,597")
       - details: list [{{ "label": "é …ç›®", "value": "æ•¸å€¼" }}] (æœ€å¤š5é …)
    2. "detailed_analysis": è©³ç´°å›ç­” (3-4å€‹é‡é»)
       - list [{{ "title": "é‡é»", "content": "å…§å®¹" }}]
    """
    return ask_gemini_json(prompt)

# --- ğŸ”¥ Flex Message UI å„ªåŒ– ---

def create_summary_flex(domain, data):
    """ç¬¬ä¸€å¼µå¡ï¼šæ•¸æ“šå„€è¡¨æ¿ (UI ä¿®å¾©ç‰ˆ)"""
    colors = {"INVESTMENT": "#ef5350", "FINANCE": "#42a5f5", "HEALTH": "#66bb6a", "KNOWLEDGE": "#ffa726"}
    theme_color = colors.get(domain, "#999999")
    
    detail_boxes = []
    details = data.get('details', [])
    if not isinstance(details, list): details = []

    for item in details[:5]:
        if isinstance(item, str): label, value = item, ""
        else: label, value = str(item.get('label', 'é …ç›®')), str(item.get('value', ''))

        detail_boxes.append({
            "type": "box", "layout": "horizontal",
            "contents": [
                {"type": "text", "text": label, "size": "sm", "color": "#aaaaaa", "flex": 2, "wrap": True}, # Labelä¹Ÿè¦wrap
                {"type": "text", "text": value, "size": "sm", "color": "#ffffff", "align": "end", "flex": 4, "wrap": True} # Valueç¶­æŒwrap
            ]
        })

    return {
        "type": "bubble",
        "size": "mega",
        "header": {
            "type": "box", "layout": "vertical", "backgroundColor": theme_color,
            "contents": [
                {"type": "text", "text": f"{domain} INTELLIGENCE", "color": "#ffffff", "weight": "bold", "size": "xxs"},
                # ğŸ”¥ å„ªåŒ– 1ï¼šæ¨™é¡Œè‡ªå‹•æ›è¡Œ (wrap=True)ï¼Œé¿å…è¢«åˆ‡æ‰
                {"type": "text", "text": str(data.get('title', 'æŸ¥è©¢çµæœ')), "weight": "bold", "size": "xl", "color": "#ffffff", "wrap": True}
            ]
        },
        "body": {
            "type": "box", "layout": "vertical", "backgroundColor": "#1e1e1e",
            "contents": [
                # ğŸ”¥ å„ªåŒ– 1ï¼šæ ¸å¿ƒæ•¸æ“šç¸®å°é©æ‡‰ (shrink-to-fit)ï¼Œé¿å… $52,000... é€™ç¨®æƒ…æ³
                *([{"type": "text", "text": str(data['main_stat']), "size": "4xl", "weight": "bold", "color": theme_color, "align": "center", "margin": "md", "adjustMode": "shrink-to-fit"}] if data.get('main_stat') else []),
                {"type": "separator", "margin": "lg", "color": "#333333"},
                {"type": "box", "layout": "vertical", "margin": "lg", "spacing": "sm", "contents": detail_boxes}
            ]
        }
    }

def create_analysis_flex(analysis_data):
    """ç¬¬äºŒå¼µå¡ï¼šè©³ç´°åˆ†æ"""
    if isinstance(analysis_data, str): analysis_data = [{"title": "åˆ†æçµæœ", "content": analysis_data}]
    elif not isinstance(analysis_data, list): analysis_data = [{"title": "æç¤º", "content": "ç„¡è©³ç´°åˆ†æè³‡æ–™"}]

    contents = []
    for section in analysis_data:
        if isinstance(section, dict):
            title = str(section.get('title', 'é‡é»'))
            content = str(section.get('content', ''))
        else:
            title, content = "é‡é»", str(section)

        contents.append({
            "type": "box", "layout": "vertical", "margin": "lg",
            "contents": [
                {"type": "text", "text": f"ğŸ“Œ {title}", "weight": "bold", "color": "#FFD700", "size": "sm", "wrap": True},
                {"type": "text", "text": content, "color": "#cccccc", "size": "sm", "wrap": True, "margin": "xs"}
            ]
        })

    return {
        "type": "bubble",
        "size": "mega",
        "body": {
            "type": "box", "layout": "vertical", "backgroundColor": "#2b2b2b",
            "contents": [
                {"type": "text", "text": "AI æ·±åº¦è§£æ", "weight": "bold", "size": "md", "color": "#ffffff", "align": "center"},
                {"type": "separator", "margin": "md", "color": "#555555"},
                *contents
            ]
        }
    }

def push_flex(user_id, alt_text, flex_content):
    url = "https://api.line.me/v2/bot/message/push"
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}"}
    payload = {"to": user_id, "messages": [{"type": "flex", "altText": alt_text, "contents": flex_content}]}
    try:
        requests.post(url, headers=headers, json=payload, verify=False)
        print("âœ… Flex Message å‚³é€æˆåŠŸ")
    except Exception as e:
        print(f"âŒ å‚³é€å¤±æ•—: {e}")

if __name__ == "__main__":
    if not LINE_CHANNEL_ACCESS_TOKEN or not LINE_USER_ID:
        print("âŒ è«‹å…ˆè¨­å®š .env ä¸­çš„ LINE_CHANNEL_ACCESS_TOKEN èˆ‡ LINE_USER_ID")
        exit()

    while True:
        print("\n" + "="*40)
        user_query = input("è«‹è¼¸å…¥æ¸¬è©¦å•é¡Œ (è¼¸å…¥ exit é›¢é–‹): ")
        if user_query.lower() in ["exit", "quit"]: break
        if not user_query.strip(): continue

        print(f"ğŸš€ é–‹å§‹åˆ†æ: {user_query}")
        
        # 1. æ„åœ–
        intent = analyze_query_intent(user_query)
        if not intent:
            print("âŒ æ„åœ–åˆ†æå¤±æ•—")
            continue
        domain = intent.get("domain", "OTHER")
        date_filter = intent.get("date_filter")
        print(f"ğŸ§  æ„åœ–: {domain} | æ—¥æœŸ: {date_filter}")

        # 2. æ’ˆè³‡æ–™
        target_dbs = list(set(DOMAIN_MAP.get(domain, []) + GLOBAL_DBS)) if domain != "KNOWLEDGE" else GLOBAL_DBS
        raw_data = {}
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
            future_to_db = {executor.submit(fetch_notion_data, db, domain, date_filter): db for db in target_dbs}
            for future in concurrent.futures.as_completed(future_to_db):
                db_name = future_to_db[future]
                res = future.result()
                if res:
                    raw_data[db_name] = res
                    print(f"  -> {db_name}: {len(res)} ç­†")

        if not raw_data:
            print("âŒ æŸ¥ç„¡è³‡æ–™")
            continue

        # 3. ç”Ÿæˆèˆ‡ç™¼é€
        print("ğŸ¤– Gemini ç”Ÿæˆä¸­...")
        ai_result = generate_rag_response(user_query, domain, raw_data)
        
        if ai_result:
            print("ğŸ“± ç™¼é€ LINE è¨Šæ¯...")
            flex1 = create_summary_flex(domain, ai_result.get("card_data", {}))
            push_flex(LINE_USER_ID, "æŸ¥è©¢æ‘˜è¦", flex1)
            
            flex2 = create_analysis_flex(ai_result.get("detailed_analysis", []))
            push_flex(LINE_USER_ID, "è©³ç´°åˆ†æ", flex2)
        else:
            print("âŒ ç”Ÿæˆå¤±æ•—")